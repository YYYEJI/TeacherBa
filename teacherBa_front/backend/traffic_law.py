# -*- coding: utf-8 -*-
"""Traffic_Law.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TJgFCmTPVG9pNDoou5kzbmMFoX9c3QKT

# Set up
"""

# Install packages
# !pip install python-dotenv
# !pip install openai
# !pip install langchain-openai
# !pip install langchain_community
# !pip install pypdf
# !pip install langchain_chroma

# Import libraries
import openai
from langchain_openai import AzureChatOpenAI
from dotenv import load_dotenv
import os
import glob
from pprint import pprint
import json
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import AzureOpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_openai import AzureOpenAIEmbeddings
from langchain_community.utils.math import cosine_similarity

# .env to memory
load_dotenv()

"""# Load"""

# Get list of all PDF files matching the pattern
pdf_files = glob.glob("/content/data/*.pdf")

pdf_docs = []
for pdf_file in pdf_files:
    loader = PyPDFLoader(pdf_file)
    docs = loader.load()
    pdf_docs.extend(docs)

    from langchain_community.document_loaders import WebBaseLoader

# 기본적인 텍스트 추출
web_loader = WebBaseLoader(
    web_path = [
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=1&cciNo=1&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=1&cciNo=1&cnpClsNo=2&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=1&cciNo=2&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=1&cciNo=2&cnpClsNo=2&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=2&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=3&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=4&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=5&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=6&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=2&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=3&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=4&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=5&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=6&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=2&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=3&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=4&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=5&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=1&cnpClsNo=6&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=2&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=3&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=2&cciNo=3&cnpClsNo=2&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=3&cciNo=1&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=3&cciNo=1&cnpClsNo=2&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=3&cciNo=1&cnpClsNo=3&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=4&cciNo=1&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=4&cciNo=1&cnpClsNo=2&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=4&cciNo=2&cnpClsNo=1&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=4&cciNo=2&cnpClsNo=2&search_put=",
        "https://www.easylaw.go.kr/CSP/CnpClsMain.laf?popMenu=ov&csmSeq=684&ccfNo=4&cciNo=2&cnpClsNo=3&search_put="

    ]
)

# 동기 로딩
web_docs = web_loader.load()

# 3. 통합 문서 리스트
all_docs = pdf_docs + web_docs

print("PDF 문서 수:", len(pdf_docs))
print("웹 문서 수:", len(web_docs))
print("전체 문서 수:", len(all_docs))
print("첫 문서 메타데이터:", all_docs[0].metadata)

"""# Text Splitting"""

# 재귀적 텍스트 분할기 초기화
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,             # 청크 크기
    chunk_overlap=200,           # 청크 중 중복되는 부분 크기
    length_function=len,         # 글자 수를 기준으로 분할
    separators=["\n\n", "\n", " ", ""],  # 구분자 - 재귀적으로 순차적으로 적용
)

# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할
all_docs = pdf_docs + web_docs # 두 문서 리스트 합치기
chunks = text_splitter.split_documents(all_docs) # 전체 문서 분할
print(f"생성된 텍스트 청크 수: {len(chunks)}")
print(f"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}")
print()

# Check Chunks
print(chunks[3].page_content)
print("=" * 50)
print(chunks[200].page_content)
print("=" * 50)
print(chunks[20].page_content)
print("=" * 50)
print(chunks[21].page_content)

"""# Embedding"""

# OpenAIEmbeddings 모델 생성
embeddings_model = AzureOpenAIEmbeddings(model="text-embedding-3-small", dimensions=1024)

# 임베딩 객체 출력
embeddings_model

# 문서 임베딩
texts = [doc.page_content for doc in chunks]
document_embeddings_openai = embeddings_model.embed_documents(texts)

# 임베딩 결과 출력
print(f"임베딩 벡터의 개수: {len(document_embeddings_openai)}")
print(f"각 벡터의 차원: {len(document_embeddings_openai[0])}")

"""# Vector Store"""

# Chroma 벡터 저장소 생성하기
chroma_db = Chroma.from_documents(
    documents = chunks,
    embedding = embeddings_model,
    persist_directory="./db_traffic" # db 저장
)

# 문서 개수 확인
print("문서 수:", len(chroma_db.get()["documents"]))  # ✅ 안전한 방식

"""# Retrieve and Simple RAG"""

# 저장된 벡터 저장소를 가져오기
chroma_db = Chroma(
    persist_directory="./db_traffic",
    embedding_function=embeddings_model
)

# mmr 검색기 생성
retriever = chroma_db.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 4, "fetch_k":10,"lambda_mult": 0.4},
)

# 검색 테스트
query = "앞지르기가 불가능한 차량에 대해 알려줘."

# 쿼리와 유사한 문서 검색
retrieved_docs = retriever.invoke(query)

print(f"쿼리: {query}")
print("검색 결과:")
for i, doc in enumerate(retrieved_docs, 1):
    score = cosine_similarity(
        [embeddings_model.embed_query(query)],
        [embeddings_model.embed_query(doc.page_content)]
        )[0][0]
    print(f"-{i}-\n{doc.page_content}\n[유사도: {score}]")
    print("-" * 100)

# Prompt 템플릿 (커스텀 예시)
from langchain_core.prompts import ChatPromptTemplate

template = """주어진 컨텍스트를 기반으로 질문에 답변하시오.

[지침]
- 컨텍스트에 있는 정보만을 사용하여 답변할 것
- 불확실한 경우 명확히 그 불확실성을 표현할 것
- 답변은 논리적이고 구조화된 형태로 제공할 것
- 답변은 한국어를 사용할 것

[컨텍스트]
{context}

[질문]
{question}

[답변]
"""

prompt = ChatPromptTemplate.from_template(template)

# 템플릿 출력
prompt.pretty_print()

from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import AzureChatOpenAI

# LLM 설정
llm = AzureChatOpenAI(
    deployment_name="gpt-4o-mini",
    temperature=0.7)

# 문서 포맷팅
def format_docs(docs):
    return "\n\n".join([f"{doc.page_content}" for doc in docs])

# RAG 체인 생성
rag_chain = (
    RunnableParallel(
        {
            "context": retriever | format_docs,
            "question": RunnablePassthrough()
        }
    )
    | prompt
    | llm
    | StrOutputParser()
)

# 체인 실행
query = "술 취한 상태에서 운전하면 어떤 처벌을 받게 되는지 알려줘."
output = rag_chain.invoke(query)

print(f"쿼리: {query}")
print("답변:")
print(output)

# import shutil
# # 파일 또는 폴더를 example.zip으로 압축
# shutil.make_archive('db_traffic', 'zip', '/content/db_traffic')
# # 압축파일 다운로드
# from google.colab import files
# files.download('db_traffic.zip')

